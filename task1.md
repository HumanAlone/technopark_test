## 1. Структура репозитория

```bash
ml-service/
├── Dockerfile                 # Докер образ
├── .gitlab-ci.yml             # CI/CD пайплайн
├── requirements.txt           # Зависимости Python
├── app/
│   ├── main.py                # Инициализация приложения FastAPI
│   ├── api.py                 # Эндпоинты
│   ├── model_loader.py        # Загрузка модели из MLflow
│   ├── utils.py               # Вспомогательный код
│   └── schemas.py             # Pydantic схемы для запроса/ответа
├── tests/
│   ├── test_api.py            # Тесты АПИ
│   └── test_model.py          # Тесты модели
├── monitoring/
│   └── metrics_collector.py   # Логика отправки метрик в ClickHouse
└── config/
    └── settings.py            # Настройки через переменные окружения
```

## 2. Шаги пайплайна CI/CD
Шаги включают в себя следующие стадии test, build и deploy:

1. Test запускает pytest для проверки кода и логики.

2. Build собирает Docker-образ для сервиса инференса. В образ копируется только код сервиса, не модель.

3. Deploy выкатывает обновленный образ на production-сервера. Сервис загружает модель с тэгом production.

## 3. Хранение и загрузка модели

Модель регистрируется и хранится в **MLflow Model Registry**. В сервис инференса подгружается следующим образом:
```python
import mlflow.sklearn

model_name = "my_model_name"
model_stage = "Production"

model_uri = f"models:/{model_name}/{model_stage}"
model = mlflow.sklearn.load_model(model_uri)
```

Обновление модели в production происходит следующим образом:  
*Новая версия модели проходит валидацию -> перевод в стадию Production в MLflow Model Registry -> запуск повторной стадии deploy в GitLab CI*

## 4. Мониторинг после релиза

Для хранения бизнес-метрик и ML-метрик используем ClickHouse, Prometheus - для инфраструктурных, визуализация при помощи Grafana.

1. Инфраструктурные метрики включают в себя загрузку CPU/RAM, latency, RPS, статус-коды ответов (4xx, 5xx).

2. Логируем входные признаки и предсказания в ClickHouse. Периодически вычисляем статистики распределения признаков и сравниваем с тренировочным распределением. Таким образом отслеживаем дрейф данных.

3. Периодически оцениваем качество модели с лагом. После поступления обратной связи вычисляем accuracy, ROC-AUC и другие метрики на накопленных фактических данных и отслеживаем дрейф концепции.